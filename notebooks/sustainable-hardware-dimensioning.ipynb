{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bd2dc3d-98f9-4c62-861e-e278f6d1e37a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#from scipy.integrate import odeint\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'core'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook setup: run this before everything\n",
    "# ============================================================\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Control figure size\n",
    "interactive_figures = False\n",
    "if interactive_figures:\n",
    "    # Normal behavior\n",
    "    %matplotlib widget\n",
    "    figsize=(9, 3)\n",
    "else:\n",
    "    # PDF export behavior\n",
    "    figsize=(14, 5)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from util import util\n",
    "#from scipy.integrate import odeint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "#from skopt.space import Space\n",
    "#from eml.net.reader import keras_reader\n",
    "from codecarbon import EmissionsTracker\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a91681-7e62-40a9-b6b8-8d641791d19b",
   "metadata": {},
   "source": [
    "# Case study: Sustainable Hardware Dimensioning\n",
    "\n",
    "With widely recognised power-hungry and expensive training algorithms, deep learning has begun to address its carbon footprint. Machine learning (ML) models have grown exponentially in size over the past few years, with some algorithms training for thousands of core-hours, and the associated energy consumption and cost have become a growing concern [Green AI paper]. \n",
    "\n",
    "Previous studies have made advances in estimating GHG emissions of computation, and have attempted in providing general and easy-to-use methodologies for estimating carbon footprint that can be applied to any computational task [Green Algorithms paper].\n",
    "\n",
    "In this work, we explore the dimension of finding the the best Hardware architecture and its dimensioning for AI algorithms, while respecting constraints in terms of carbon emissions. Previous work [HADA paper] has focused on HW Dimensioning for AI algorithms with constraints on budget, time and solution quality. This problem is called Hardware Dimensioning. In this work, we aim at extending this approach by also considering constraints on carbon emissions of the computations, and we name this problem Sustainable Hardware Dimensioning.\n",
    "\n",
    "The HADA approach is based on the Empirical Model Learning paradigm [EML paper], which integrates Machine Learning (ML) models into an optimisation problem. The key idea is to integrate domain knowledge held by experts with data-driven models that learn the relationships between HW requirements and AI algorithm performances, which would be very complex to express formally in a suitable model. The approach starts with benchmarking multiple AI algorithms on different HW resources, generating data used to train ML models; then, optimisation is used to find the best [HW configuration](https://www.sciencedirect.com/topics/computer-science/hardware-configuration) that respects user-defined constraints.\n",
    "\n",
    "# Methodology\n",
    "\n",
    "At the basis of our approach is the Empirical Model Learning (EML) paradigm. Broadly speaking, EML deals with solving declarative optimisation models with a complex component $h$, which represents the relation between variables which can be acted upon $x$ (the decision variables) and the observables related to the system considered; the function $h(x) = y$ describes this relationships. As the $h(x)$ is complex, we cannot optimise directly over it. Hence, we exploit empirical knowledge to build a surrogate model $h_\\theta(x)$ learned from data, where $\\theta$ is the parameter vector.\n",
    "\n",
    "HADA (HArdware Dimensioning of AI Algorithms), is then constituted of three main phases\n",
    "\n",
    "1. data set collection (benchmarking phase) - an initial phase to collect the data set by running multiple times the target algorithms, under different configurations;\n",
    "2. surrogate model creation - once a training set is available, a set of ML models is then trained on such data and then these models are encoded as a set of variables and constraints following EML paradigm;\n",
    "3. optimisation – post the user-defined constraints and objective function on top of the combinatorial structure formed by the encoded ML models and the domain-knowledge constraints, and finally solve the optimisation model (either until an optimal solution or a time limit is reached.\n",
    "\n",
    "## Dataset Collection\n",
    "\n",
    "The training set was built based on grounding the two stochastic algorithms, i.e., anticipate and contingency [32, 4] from the energy management system domain. The two algorithms calculate the amount of energy that must be produced by the energy system to meet the required load, minimising the total energy cost over the daily time horizon and by taking into account the uncertainty. Both the algorithms divide the daily time horizon into 96 15-minutes time intervals.\n",
    "\n",
    "### Input data\n",
    "\n",
    "The input data is a set of 30 different instance realisations, each one representing one daily time horizon. For each day, we have **Load**, which is a 96-valued vector of the load observations sampled at each interval (every 15 minutes over the course of a day), and **PV**, a 96-valued vector representing the observations of available Photovoltaic energy production. Here we can see an example of the first two instances:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "827956df-de8f-4abb-8a1c-58433cd7c7a9",
   "metadata": {},
   "source": [
    "# Data exploration: look at the input data\n",
    "data = util.display_instances_data()\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62d807-6da6-4d06-b71e-fdea0b7dcf32",
   "metadata": {},
   "source": [
    "Since the objective of the two algorithms is to minimize the total energy cost, as input file we also have the grid electricity price at each our of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6daadda-16fc-47f9-903a-e818d628217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util.display_prices_data()\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f2c21-2be7-4b24-87ce-e48ac3cfb4ad",
   "metadata": {},
   "source": [
    "The base version of HADA involves measuring the solution cost, the runtime and the average memory usage for the target algorithm. In the next section we will see the additional metrics that were added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302f4f4-0472-48c8-b1b4-1c3e96faaecd",
   "metadata": {},
   "source": [
    "### Measuring Carbon Emissions\n",
    "\n",
    "In order to extend HADA for taking into account sustainability, we need to measure the carbon emissions for running the algorithms during the benchmark phase. A simple tool to do so is [codecarbon](https://mlco2.github.io/codecarbon/index.html), which is a python package offering useful tools for tracking the emissions resulting from executing code execution.\n",
    "\n",
    "The CO2e emission tracking tool offered by codecarbon can be used in [different modalities](https://mlco2.github.io/codecarbon/usage.html): as an Explicit Object (instantiating a EmissionsTracker object and pass it as a parameter to function calls to start and stop the emissions tracking of the compute section), as a Context Manager (recommended for monitoring a specific code block) or as a Decorator (recommended for monitoring training functions). For example, let's track the emissions of running the ANTICIPATE algorithm. Let's say we would like to solve instance 5 with 4 scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca68ef-3fb4-4cb1-971b-08ca46795d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = 4\n",
    "instance = 5\n",
    "project_name = f\"anticipate-ins-{instance}-ns-{scenarios}\"\n",
    "output_dir = '../data/'\n",
    "\n",
    "# Codecarbon emission tracker\n",
    "tracker = EmissionsTracker(project_name=project_name, \n",
    "                           log_level='ERROR', \n",
    "                           output_dir=output_dir)\n",
    "\n",
    "with tracker as t:\n",
    "    sol_cost, run_final, mem_final = util.online_ant(scenarios=scenarios, instance=instance, file='InstancesTest.csv')\n",
    "\n",
    "print(f\"The solution cost (in keuro) is: {sol_cost:.2f}\")\n",
    "print(f\"The runtime (in sec) is: {run_final:.2f}\")\n",
    "print(f\"Avg memory used (in MB) is: {mem_final:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cb8ab5-e1a3-44d3-ba2b-0e659f5740b2",
   "metadata": {},
   "source": [
    "This tracks the emissions of the `online_ant` function by using the codecarbon `EmissionTracker` as a context manager. By default, codecarbon saves the tracking data to a .csv file, named `emissions.csv`. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5964c5bf-a1fe-4ddd-bf29-7dee92a522a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions = util.display_emissions_data()\n",
    "display(emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b1ba2c-07e6-4534-8a9c-b9b7c13a00d4",
   "metadata": {},
   "source": [
    "(**NOTE:** maybe a table is not the most suitable representation) As we can see, Codecarbon keeps track of a series of metrics. For this project, we decided to include the following metrics in the training set to generate:\n",
    "\n",
    "* `emissions`: the total emissions of CO2eq (kg) (**NOTE:** add a brief explanation about how codecarbon computes the emissions);\n",
    "* `emission_rate`: the amount of CO2eq emissions per second (kg/s);\n",
    "* `cpu_energy`: the energy consumed by the cpu;\n",
    "* `ram_energy`: the energy consumed by the ram;\n",
    "* `tot_energy`: the total energy consumed;\n",
    "* `country`, `region`: the country and region where the computation took place;\n",
    "* `cpu_count`: the number of cores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b734b0-04ac-4e50-9809-e4318128d34e",
   "metadata": {},
   "source": [
    "### Benchmarking\n",
    "\n",
    "For the benchmarking phase, the ANTICIPATE and CONTINGECY algorithms were run on each instance 100 times, each time considering a different number of the configurable parameter (from 1 to 100 traces/scenarios). This value is taken directly from the HADA paper, according to which running the algorithms on each instance 100 times sufficiently explores the parameter space [Hada paper, 4]. Then, the training set of each algorithm will be of 3,000 records (100 runs x 30 instances). \n",
    "\n",
    "Since for the HADA approach is recommended to collect data relative to different Hardware configurations, i executed the benchmarking phase on my personal laptop [Insert specifications], and on [Leonardo](https://leonardo-supercomputer.cineca.eu/), an HPC System hosted by CINECA. After the benchmark phase, the collected dataset will look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f44ad-78a4-4132-a3a4-6aa9f5526c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'contingency_mbp19.csv'\n",
    "benchmark_data = util.display_benchmark_data(filename)\n",
    "display(benchmark_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c69b1-a4ee-4f66-b0b7-6cb4a3e0de45",
   "metadata": {},
   "source": [
    "## Data exploration\n",
    "\n",
    "Let's have a look at the data produced during benchmark phase, to gather some insights\n",
    "\n",
    "### Load and combine data\n",
    "\n",
    "We first load the data and add identifying columns to make it easy to filter and compare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c34bde8-3c01-4ba7-98fd-6beee5075916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for each combination of algorithm and platform\n",
    "files = {\n",
    "    \"anticipate_mbp19\": \"anticipate_mbp19.csv\",\n",
    "    \"anticipate_leonardo\": \"anticipate_leonardo.csv\",\n",
    "    \"contingency_mbp19\": \"contingency_mbp19.csv\",\n",
    "    \"contingency_leonardo\": \"contingency_leonardo.csv\"\n",
    "}\n",
    "\n",
    "# load each files and add identifiers\n",
    "dataframes = []\n",
    "for key, file in files.items():\n",
    "    algorithm, platform = key.split('_')\n",
    "    df = util.read_benchmark_file(file)\n",
    "    df['algorithm'] = algorithm\n",
    "    df['platform'] = platform\n",
    "    dataframes.append(df)\n",
    "\n",
    "# concatenate all dataframes into one for analysis\n",
    "data = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4792416-e331-4463-b487-64c777376f3c",
   "metadata": {},
   "source": [
    "### Basic data overview\n",
    "\n",
    "To get a high-level summary of each metric, we run `.describe()` for statistical insights and `.info()` to check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201cc366-93b2-4029-98d6-54f52e5362f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop some of the columns\n",
    "columns = ['nScenarios','nTraces','cpuCount']\n",
    "data_overview = data.drop(columns=columns)\n",
    "\n",
    "print(data_overview.describe())\n",
    "print(\"=\"*50)\n",
    "print(data_overview.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3765b51-c0f7-4359-8b67-bfef726612b3",
   "metadata": {},
   "source": [
    "Notice that the min for memPeak is 0.12. That's because the values for the memory peak consumption recorded on leonardo are strangely low, thus also bringing the average down. It is strange also because in the instance with memPeak 0.12, the average memory is higher, which shouldn’t be possible. The benchmark runs on Leonardo should have been repeated. Unfortunately, the recent weather emergency in Emilia-Romagna caused the interruptions of the HPC services offered by Cineca."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a109a6-045b-444c-b9d0-0bf37dac97a1",
   "metadata": {},
   "source": [
    "### Categorical analysis\n",
    "\n",
    "Analyze categorical columns like `algorithm`, `platform`, `country` and `region` to understand the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a257626b-c56f-4a57-9e30-e30f3620b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count distribution for categorical columns\n",
    "print(data['algorithm'].value_counts())\n",
    "print(data['platform'].value_counts())\n",
    "print(data['country'].value_counts())\n",
    "print(data['region'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f429cde-d775-47cc-b9bb-f60d7e51a957",
   "metadata": {},
   "source": [
    "Notice that we \"canada\" and \"quebec\" in many entries for the country and region. That's not because i travelled, even though i'd like to. That is something taken from codecarbon, so there should be some problem there when tracking emissions. The problem with these values is that they influence the way in which the carbon footprint is computed. That's because codecarbon uses data relative to the carbon intensity of a given country, so that could change the final result. For example, we have 4.31e-06 as emission rate for italy and 3.00e-08 for canada. Notice that we could also remove this column, since its values are fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42684030-a5a5-480b-bc62-57730df9afdf",
   "metadata": {},
   "source": [
    "### Exploring performance metrics\n",
    "\n",
    "Since `sol(keuro)`, `time(sec)`, `memAvg(MB)` and `memPeak(MB)` represent performance metrics, visualize and compare them across algorithms and platforms. First, we compare solution cost and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eeee91-5283-493e-ba1d-ab784aca5659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Cost Comparison by Algorithm and Platform\n",
    "sns.boxplot(data=data, x='algorithm', y='sol(keuro)', hue='platform')\n",
    "plt.title('Solution Cost Comparison by Algorithm and Platform')\n",
    "plt.show()\n",
    "\n",
    "# Time Required Comparison\n",
    "sns.boxplot(data=data, x='algorithm', y='time(sec)', hue='platform')\n",
    "plt.title('Execution Time Comparison by Algorithm and Platform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e5b94-06eb-4da5-8f8c-792d2966b128",
   "metadata": {},
   "source": [
    "We can notice that solution cost is tipycally higher for contingency. While for the execution time, results are a bit strange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e8168-6cca-49cc-9c7a-a75184d26040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Memory Usage\n",
    "sns.boxplot(data=data, x='algorithm', y='memAvg(MB)', hue='platform')\n",
    "plt.title('Average Memory Usage by Algorithm and Platform')\n",
    "plt.show()\n",
    "\n",
    "# Peak Memory Usage\n",
    "sns.boxplot(data=data, x='algorithm', y='memPeak(MB)', hue='platform')\n",
    "plt.title('Peak Memory Usage by Algorithm and Platform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c1b227-e023-44a7-9f4b-79c5c97448c4",
   "metadata": {},
   "source": [
    "### Energy and Emission Analysis\n",
    "\n",
    "Explore the CO2 emissions `CO2e(kg)` and energy consumption metrics to compare environmental impact across algorithms and platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f4c80-d9f3-4fa6-86b9-f4cbce638436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO2 Emissions by Algorithm and Platform\n",
    "sns.boxplot(data=data, x='algorithm', y='CO2e(kg)', hue='platform')\n",
    "plt.title('CO2 Emissions by Algorithm and Platform')\n",
    "plt.show()\n",
    "\n",
    "# Energy Consumption: CPU, RAM, and Total\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.boxplot(data=data, x='algorithm', y='cpuEnergy(kW)', hue='platform', ax=axes[0])\n",
    "axes[0].set_title('CPU Energy Consumption')\n",
    "\n",
    "sns.boxplot(data=data, x='algorithm', y='ramEnergy(kW)', hue='platform', ax=axes[1])\n",
    "axes[1].set_title('RAM Energy Consumption')\n",
    "\n",
    "sns.boxplot(data=data, x='algorithm', y='totEnergy(kW)', hue='platform', ax=axes[2])\n",
    "axes[2].set_title('Total Energy Consumption')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bfbfe-efc8-4415-9f89-b43baa0dde1b",
   "metadata": {},
   "source": [
    "### Performance vs. Emissions Correlation\n",
    "\n",
    "Analyze if there's a correlation between performance and environmental metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e24569-39b4-46a2-af64-8632fc8cc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numeric columns\n",
    "correlation_matrix = data[['sol(keuro)', 'time(sec)', 'CO2e(kg)', 'totEnergy(kW)']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Between Performance and Emissions Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a950d182-6aa5-4635-abe2-2731490fe0a4",
   "metadata": {},
   "source": [
    "### Comparison of Core Counts\n",
    "\n",
    "Check if CPU core count impacts solution time or energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e887a7-f4af-47a3-bee4-f7d36092059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Time vs. CPU Count\n",
    "sns.scatterplot(data=data, x='cpuCount', y='time(sec)', hue='algorithm', style='platform')\n",
    "plt.title('Execution Time vs. CPU Count')\n",
    "plt.show()\n",
    "\n",
    "# Total Energy vs. CPU Count\n",
    "sns.scatterplot(data=data, x='cpuCount', y='totEnergy(kW)', hue='algorithm', style='platform')\n",
    "plt.title('Total Energy vs. CPU Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230919af-95e0-48f3-9858-6595742af599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
